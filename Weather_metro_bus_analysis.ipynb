{
  "metadata": {
    "name": "Weather_metro_bus_analysis",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val weatherFilePath \u003d \"weather-clean.csv\"\r\n\r\nval weatherDf \u003d spark.read\r\n  .option(\"header\", \"true\") \r\n  .option(\"multiLine\", \"true\")\r\n  .option(\"inferSchema\", \"true\")\r\n  .option(\"escape\", \"\\\"\")\r\n  .csv(weatherFilePath)\r\n\r\nweatherDf.printSchema()\r\nweatherDf.show(5, truncate \u003d false)\r\n\r\nval busDF \u003d spark.read.parquet(\"bus-clean.parquet\")\r\nval subwayDF \u003d spark.read.parquet(\"subway-clean.parquet\")\r\n\r\nbusDF.printSchema()\r\nbusDF.show(5, truncate \u003d false)\r\n\r\nsubwayDF.printSchema()\r\nsubwayDF.show(5, truncate \u003d false)"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val weatherDfWithTimestamp \u003d weatherDf\n  .withColumn(\"datetime_string\", concat(col(\"Date\"), lit(\" \"), col(\"Hour_of_day\")))\n  .withColumn(\"datetime\", to_timestamp(col(\"datetime_string\"), \"yyyy/M/d H\"))\n  .drop(\"datetime_string\", \"Date\", \"Hour_of_day\")\n  .withColumnRenamed(\" HeavyFog\", \"HeavyFog\")\n  .withColumnRenamed(\" Thunder\", \"Thunder\")\n  .withColumnRenamed(\" IcePellet\", \"IcePellet\")\n  .withColumnRenamed(\" Hail\", \"Hail\")\n  .withColumnRenamed(\" Glaze\", \"Glaze\")\n  .withColumnRenamed(\" Dust\", \"Dust\")\n  .withColumnRenamed(\" Haze\", \"Haze\")\n  .withColumnRenamed(\" BlowingSnow\", \"BlowingSnow\")\n  .withColumnRenamed(\" Tornado\", \"Tornado\")\n  .withColumnRenamed(\" HighWind\", \"HighWind\")\n  .withColumnRenamed(\" BlowingSpray\", \"BlowingSpray\")\n  .withColumnRenamed(\" Mist\", \"Mist\")\n  .withColumnRenamed(\" Drizzle\", \"Drizzle\")\n  .withColumnRenamed(\" FreezingDrizzle\", \"FreezingDrizzle\")\n  .withColumnRenamed(\" Rain\", \"Rain\")\n  .withColumnRenamed(\" FreezingRain\", \"FreezingRain\")\n  .withColumnRenamed(\" Snow\", \"Snow\")\n  .withColumnRenamed(\" UnknownPrecipitation\", \"UnknownPrecipitation\")\n  .withColumnRenamed(\" GroundFog\", \"GroundFog\")\n  .withColumnRenamed(\" IceFog\", \"IceFog\")\n  .withColumnRenamed(\" DailyPrecipitationValue\", \"DailyPrecipitationValue\")\n  .withColumnRenamed(\" DailySnowDepthValue\", \"DailySnowDepthValue\")\n  .withColumnRenamed(\" DailySnowfallValue\", \"DailySnowfallValue\")\n\nweatherDfWithTimestamp.printSchema()\nweatherDfWithTimestamp.show(5, truncate \u003d false)"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val weatherTypes \u003d Seq(\r\n  \"Fog\", \"HeavyFog\", \"Thunder\", \"IcePellet\", \"Hail\", \"Glaze\", \"Dust\",\r\n  \"Haze\", \"BlowingSnow\", \"Tornado\", \"HighWind\", \"BlowingSpray\", \"Mist\",\r\n  \"Drizzle\", \"FreezingDrizzle\", \"Rain\", \"FreezingRain\", \"Snow\",\r\n  \"UnknownPrecipitation\", \"GroundFog\", \"IceFog\"\r\n)\r\n\r\nval weathertypeDF \u003d weatherDfWithTimestamp.select(\r\n  col(\"datetime\"),\r\n  coalesce(\r\n    weatherTypes.map(weatherType \u003d\u003e\r\n      when(col(weatherType) \u003d\u003d\u003d 1, weatherType)\r\n    ): _*\r\n  ).alias(\"HourlyWeatherType\"),\r\n  col(\"HourlyDryBulbTemperature\"), \r\n  col(\"HourlyPrecipitationValue\"),\r\n  col(\"DailyPrecipitationValue\")\r\n)\r\nweathertypeDF.printSchema()\r\nweathertypeDF.show(5, false)\r\n\r\nval Bus_Hourly_Temp_Ridership_DF \u003d busDF\r\n  .withColumnRenamed(\"transit_timestamp\", \"datetime\")\r\n  .join(weathertypeDF, Seq(\"datetime\"), \"inner\")\r\n  .select(col(\"datetime\"), col(\"HourlyDryBulbTemperature\").cast(\"double\"), col(\"total_ridership\"))\r\n  \r\nBus_Hourly_Temp_Ridership_DF.printSchema()\r\nBus_Hourly_Temp_Ridership_DF.show(5, truncate \u003d false)\r\n\r\n\r\nval Bus_Hourly_Prec_Ridership_DF \u003d busDF.withColumnRenamed(\"transit_timestamp\", \"datetime\").join(weathertypeDF, Seq(\"datetime\"), \"inner\")\r\n  .select(col(\"datetime\"), col(\"HourlyPrecipitationValue\").cast(\"double\"), col(\"total_ridership\"))\r\n  \r\nBus_Hourly_Prec_Ridership_DF.printSchema()\r\nBus_Hourly_Prec_Ridership_DF.show(5, truncate \u003d false)\r\n\r\n\r\nval Bus_Hourly_Weath_Ridership_DF \u003d busDF\r\n  .withColumnRenamed(\"transit_timestamp\", \"datetime\")\r\n  .join(weathertypeDF, Seq(\"datetime\"), \"inner\")\r\n  .select(\r\n    col(\"datetime\"),\r\n    col(\"HourlyWeatherType\"),\r\n    col(\"total_ridership\")\r\n  )\r\n\r\nBus_Hourly_Weath_Ridership_DF.printSchema()\r\nBus_Hourly_Weath_Ridership_DF.show(5, false)\r\n\r\n\r\nval Bus_Daily_Temp_Ridership_DF \u003d busDF.withColumnRenamed(\"transit_timestamp\", \"datetime\").join(weathertypeDF, Seq(\"datetime\"), \"inner\")\r\n  .groupBy(to_date(col(\"datetime\")).as(\"date\"))\r\n  .agg(avg(col(\"HourlyDryBulbTemperature\").cast(\"double\")).as(\"avg_temperature\"), sum(col(\"total_ridership\")).as(\"total_ridership\"))\r\n  .orderBy(col(\"date\").asc)\r\n  \r\nBus_Daily_Temp_Ridership_DF.printSchema()\r\nBus_Daily_Temp_Ridership_DF.show(5, truncate \u003d false)\r\n\r\n\r\nval Bus_Daily_Prec_Ridership_DF \u003d busDF.withColumnRenamed(\"transit_timestamp\", \"datetime\").join(weathertypeDF, Seq(\"datetime\"), \"inner\")\r\n  .groupBy(to_date(col(\"datetime\")).as(\"date\"))\r\n  .agg(max(col(\"DailyPrecipitationValue\")).as(\"daily_precipitation\"), sum(col(\"total_ridership\")).as(\"total_ridership\"))\r\n  .orderBy(col(\"date\").asc)\r\n  \r\nBus_Daily_Prec_Ridership_DF.printSchema()\r\nBus_Daily_Prec_Ridership_DF.show(5, truncate \u003d false)\r\n\r\n\r\n\r\n// // 地铁数据集\r\nval Metro_Hourly_Temp_Ridership_DF \u003d subwayDF.withColumnRenamed(\"transit_timestamp\", \"datetime\").join(weathertypeDF, Seq(\"datetime\"), \"inner\")\r\n  .select(col(\"datetime\"), col(\"HourlyDryBulbTemperature\").cast(\"double\"), col(\"total_ridership\"))\r\n  \r\nMetro_Hourly_Temp_Ridership_DF.printSchema()\r\nMetro_Hourly_Temp_Ridership_DF.show(5, truncate \u003d false)\r\n\r\n\r\nval Metro_Hourly_Prec_Ridership_DF \u003d subwayDF.withColumnRenamed(\"transit_timestamp\", \"datetime\").join(weathertypeDF, Seq(\"datetime\"), \"inner\")\r\n  .select(col(\"datetime\"), col(\"HourlyPrecipitationValue\").cast(\"double\"), col(\"total_ridership\"))\r\n  \r\nMetro_Hourly_Prec_Ridership_DF.printSchema()\r\nMetro_Hourly_Prec_Ridership_DF.show(5, truncate \u003d false)\r\n\r\n\r\nval Metro_Hourly_Weath_Ridership_DF \u003d subwayDF\r\n  .withColumnRenamed(\"transit_timestamp\", \"datetime\")\r\n  .join(weathertypeDF, Seq(\"datetime\"), \"inner\")\r\n  .select(\r\n    col(\"datetime\"),\r\n    col(\"HourlyWeatherType\"),\r\n    col(\"total_ridership\")\r\n  )\r\n  \r\nMetro_Hourly_Weath_Ridership_DF.printSchema()\r\nMetro_Hourly_Weath_Ridership_DF.show(5, truncate \u003d false)\r\n\r\n\r\nval Metro_Daily_Temp_Ridership_DF \u003d subwayDF.withColumnRenamed(\"transit_timestamp\", \"datetime\").join(weathertypeDF, Seq(\"datetime\"), \"inner\")\r\n  .groupBy(to_date(col(\"datetime\")).as(\"date\"))\r\n  .agg(avg(col(\"HourlyDryBulbTemperature\").cast(\"double\")).as(\"avg_temperature\"), sum(col(\"total_ridership\")).as(\"total_ridership\"))\r\n  .orderBy(col(\"date\").asc)\r\n  \r\nMetro_Daily_Temp_Ridership_DF.printSchema()\r\nMetro_Daily_Temp_Ridership_DF.show(5, truncate \u003d false)\r\n\r\n\r\nval Metro_Daily_Prec_Ridership_DF \u003d subwayDF.withColumnRenamed(\"transit_timestamp\", \"datetime\").join(weathertypeDF, Seq(\"datetime\"), \"inner\")\r\n  .groupBy(to_date(col(\"datetime\")).as(\"date\"))\r\n  .agg(max(col(\"DailyPrecipitationValue\")).as(\"daily_precipitation\"), sum(col(\"total_ridership\")).as(\"total_ridership\"))\r\n  .orderBy(col(\"date\").asc)\r\n  \r\nMetro_Daily_Prec_Ridership_DF.printSchema()\r\nMetro_Daily_Prec_Ridership_DF.show(5, truncate \u003d false)"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Bus EDA\n// Perform descriptive statistics and distribution analysis for continuous variables such as temperature and precipitation\nimport org.apache.spark.sql.DataFrame\nval temperatureStats \u003d Bus_Hourly_Temp_Ridership_DF\n  .select(\n    min(col(\"HourlyDryBulbTemperature\")).as(\"min_temperature\"),\n    max(col(\"HourlyDryBulbTemperature\")).as(\"max_temperature\"),\n    avg(col(\"HourlyDryBulbTemperature\")).as(\"avg_temperature\"),\n    stddev(col(\"HourlyDryBulbTemperature\")).as(\"stddev_temperature\"),\n    skewness(col(\"HourlyDryBulbTemperature\")).as(\"skewness_temperature\"),\n    kurtosis(col(\"HourlyDryBulbTemperature\")).as(\"kurtosis_temperature\")\n  )\n\ntemperatureStats.show(truncate \u003d false)\n\nval temperatureDistribution \u003d Bus_Hourly_Temp_Ridership_DF\n  .groupBy(col(\"HourlyDryBulbTemperature\"))\n  .agg(count(\"*\").as(\"count\"))\n  .orderBy(col(\"HourlyDryBulbTemperature\").asc)\n\ntemperatureDistribution.show(truncate \u003d false)\nprintln(\"temperatureDistribution DataFrame:\")\nz.show(temperatureDistribution)"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Bus EDA\n// Perform comparative analysis of passenger numbers under different weather types (such as fog, thunderstorms, etc.)\nval weatherRidershipAnalysis \u003d Bus_Hourly_Weath_Ridership_DF\n  .groupBy(col(\"HourlyWeatherType\"))\n  .agg(\n    avg(col(\"total_ridership\")).alias(\"avg_ridership\"),\n    min(col(\"total_ridership\")).alias(\"min_ridership\"),\n    max(col(\"total_ridership\")).alias(\"max_ridership\"),\n    count(col(\"total_ridership\")).alias(\"count\")\n  )\n  .orderBy(col(\"avg_ridership\").desc);\n\nweatherRidershipAnalysis.printSchema();\nweatherRidershipAnalysis.show(false);\n\nprintln(\"weatherRidershipAnalysis DataFrame:\")\nz.show(weatherRidershipAnalysis)"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Use line charts to show the changes in the number of passengers at different hours and dates\nprintln(\"Bus_Hourly_Temp_Ridership_DF DataFrame:\")\nz.show(Bus_Hourly_Temp_Ridership_DF)"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Use line charts to show the changes in the number of passengers at different dates\nprintln(\"Bus_Daily_Temp_Ridership_DF DataFrame:\")\nz.show(Bus_Daily_Temp_Ridership_DF)"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Perform comparative analysis of passenger numbers under different weather types (such as fog, thunderstorms, etc.)\nval weatherRidershipAnalysis \u003d Metro_Hourly_Weath_Ridership_DF\n  .groupBy(col(\"HourlyWeatherType\"))\n  .agg(\n    avg(col(\"total_ridership\")).alias(\"avg_ridership\"),\n    min(col(\"total_ridership\")).alias(\"min_ridership\"),\n    max(col(\"total_ridership\")).alias(\"max_ridership\"),\n    count(col(\"total_ridership\")).alias(\"count\")\n  )\n  .orderBy(col(\"avg_ridership\").desc);\n\nweatherRidershipAnalysis.printSchema();\nweatherRidershipAnalysis.show(false);\n\nprintln(\"weatherRidershipAnalysis DataFrame:\")\nz.show(weatherRidershipAnalysis)"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Use line charts to show the changes in the number of passengers at different hours and dates\nprintln(\"Metro_Hourly_Temp_Ridership_DF DataFrame:\")\nz.show(Metro_Hourly_Temp_Ridership_DF)"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Use line charts to show the changes in the number of passengers at different dates\nprintln(\"Metro_Daily_Temp_Ridership_DF DataFrame:\")\nz.show(Metro_Daily_Temp_Ridership_DF)"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.ml.feature.VectorAssembler\r\nimport org.apache.spark.ml.regression.LinearRegression\r\nimport org.apache.spark.ml.evaluation.RegressionEvaluator\r\nimport org.apache.spark.sql.functions._\r\n\r\nval filteredData \u003d Bus_Hourly_Temp_Ridership_DF.filter(col(\"HourlyDryBulbTemperature\").isNotNull)\r\n\r\nval assembler \u003d new VectorAssembler()\r\n  .setInputCols(Array(\"HourlyDryBulbTemperature\"))\r\n  .setOutputCol(\"features\")\r\n  .setHandleInvalid(\"keep\")\r\n\r\nval dataWithFeatures \u003d assembler.transform(filteredData)\r\n  .select(col(\"total_ridership\").alias(\"label\"), col(\"features\"))\r\n\r\nval Array(trainingData, testData) \u003d dataWithFeatures.randomSplit(Array(0.8, 0.2), seed\u003d42)\r\n\r\nval lr \u003d new LinearRegression()\r\n\r\nval lrModel \u003d lr.fit(trainingData)\r\n\r\nval predictions \u003d lrModel.transform(testData)\r\nval evaluator \u003d new RegressionEvaluator()\r\n  .setLabelCol(\"label\")\r\n  .setPredictionCol(\"prediction\")\r\n  .setMetricName(\"r2\")\r\n\r\nval r2 \u003d evaluator.evaluate(predictions)\r\nprintln(s\"R-squared \u003d $r2\")\r\n\r\nprintln(s\"Coefficients: ${lrModel.coefficients}\")\r\nprintln(s\"Intercept: ${lrModel.intercept}\")\r\n\r\nval correlation \u003d filteredData.stat.corr(\"HourlyDryBulbTemperature\", \"total_ridership\")\r\nprintln(s\"Correlation coefficient: $correlation\")"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.ml.feature.VectorAssembler\r\nimport org.apache.spark.ml.regression.LinearRegression\r\nimport org.apache.spark.ml.evaluation.RegressionEvaluator\r\nimport org.apache.spark.sql.functions._\r\n//bus\r\nval filteredData \u003d Bus_Hourly_Prec_Ridership_DF.filter(col(\"HourlyPrecipitationValue\").isNotNull)\r\nval assembler \u003d new VectorAssembler()\r\n  .setInputCols(Array(\"HourlyPrecipitationValue\"))\r\n  .setOutputCol(\"features\")\r\n  .setHandleInvalid(\"keep\")\r\n\r\nval dataWithFeatures \u003d assembler.transform(filteredData)\r\n  .select(col(\"total_ridership\").alias(\"label\"), col(\"features\"))\r\n\r\nval Array(trainingData, testData) \u003d dataWithFeatures.randomSplit(Array(0.8, 0.2), seed\u003d42)\r\n\r\nval lr \u003d new LinearRegression()\r\n\r\nval lrModel \u003d lr.fit(trainingData)\r\n\r\nval predictions \u003d lrModel.transform(testData)\r\nval evaluator \u003d new RegressionEvaluator()\r\n  .setLabelCol(\"label\")\r\n  .setPredictionCol(\"prediction\")\r\n  .setMetricName(\"r2\")\r\n\r\nval r2 \u003d evaluator.evaluate(predictions)\r\nprintln(s\"R-squared \u003d $r2\")\r\n\r\nprintln(s\"Coefficients: ${lrModel.coefficients}\")\r\nprintln(s\"Intercept: ${lrModel.intercept}\")\r\n\r\nval correlation \u003d filteredData.stat.corr(\"HourlyPrecipitationValue\", \"total_ridership\")\r\nprintln(s\"Correlation coefficient: $correlation\")"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.ml.feature.VectorAssembler\r\nimport org.apache.spark.ml.regression.LinearRegression\r\nimport org.apache.spark.ml.evaluation.RegressionEvaluator\r\nimport org.apache.spark.sql.functions._\r\n//Metro\r\nval filteredData \u003d Metro_Hourly_Temp_Ridership_DF.filter(col(\"HourlyDryBulbTemperature\").isNotNull)\r\n\r\nval assembler \u003d new VectorAssembler()\r\n  .setInputCols(Array(\"HourlyDryBulbTemperature\"))\r\n  .setOutputCol(\"features\")\r\n  .setHandleInvalid(\"keep\")\r\n\r\nval dataWithFeatures \u003d assembler.transform(filteredData)\r\n  .select(col(\"total_ridership\").alias(\"label\"), col(\"features\"))\r\n\r\nval Array(trainingData, testData) \u003d dataWithFeatures.randomSplit(Array(0.8, 0.2), seed\u003d42)\r\n\r\nval lr \u003d new LinearRegression()\r\n\r\nval lrModel \u003d lr.fit(trainingData)\r\n\r\nval predictions \u003d lrModel.transform(testData)\r\nval evaluator \u003d new RegressionEvaluator()\r\n  .setLabelCol(\"label\")\r\n  .setPredictionCol(\"prediction\")\r\n  .setMetricName(\"r2\")\r\n\r\nval r2 \u003d evaluator.evaluate(predictions)\r\nprintln(s\"R-squared \u003d $r2\")\r\n\r\nprintln(s\"Coefficients: ${lrModel.coefficients}\")\r\nprintln(s\"Intercept: ${lrModel.intercept}\")\r\n\r\nval correlation \u003d filteredData.stat.corr(\"HourlyDryBulbTemperature\", \"total_ridership\")\r\nprintln(s\"Correlation coefficient: $correlation\")"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.ml.feature.VectorAssembler\r\nimport org.apache.spark.ml.regression.LinearRegression\r\nimport org.apache.spark.ml.evaluation.RegressionEvaluator\r\nimport org.apache.spark.sql.functions._\r\n//Metro\r\nval filteredData \u003d Metro_Hourly_Prec_Ridership_DF.filter(col(\"HourlyPrecipitationValue\").isNotNull)\r\n// z.show(filteredData)\r\nval assembler \u003d new VectorAssembler()\r\n  .setInputCols(Array(\"HourlyPrecipitationValue\"))\r\n  .setOutputCol(\"features\")\r\n  .setHandleInvalid(\"keep\")\r\n\r\nval dataWithFeatures \u003d assembler.transform(filteredData)\r\n  .select(col(\"total_ridership\").alias(\"label\"), col(\"features\"))\r\n\r\nval Array(trainingData, testData) \u003d dataWithFeatures.randomSplit(Array(0.8, 0.2), seed\u003d42)\r\n\r\nval lr \u003d new LinearRegression()\r\n\r\nval lrModel \u003d lr.fit(trainingData)\r\n\r\nval predictions \u003d lrModel.transform(testData)\r\nval evaluator \u003d new RegressionEvaluator()\r\n  .setLabelCol(\"label\")\r\n  .setPredictionCol(\"prediction\")\r\n  .setMetricName(\"r2\")\r\n\r\nval r2 \u003d evaluator.evaluate(predictions)\r\nprintln(s\"R-squared \u003d $r2\")\r\n\r\nprintln(s\"Coefficients: ${lrModel.coefficients}\")\r\nprintln(s\"Intercept: ${lrModel.intercept}\")\r\n\r\nval correlation \u003d filteredData.stat.corr(\"HourlyPrecipitationValue\", \"total_ridership\")\r\nprintln(s\"Correlation coefficient: $correlation\")"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.functions._\r\n//Bus\r\nval weatherTypeStats \u003d Bus_Hourly_Weath_Ridership_DF\r\n  .na.fill(\"Clear\", Seq(\"HourlyWeatherType\")) \r\n  .groupBy(\"HourlyWeatherType\")\r\n  .agg(\r\n    avg(\"total_ridership\").alias(\"mean_ridership\"),\r\n    min(\"total_ridership\").alias(\"min_ridership\"),\r\n    max(\"total_ridership\").alias(\"max_ridership\"),\r\n    stddev(\"total_ridership\").alias(\"stddev_ridership\")\r\n  )\r\n  .orderBy(\"mean_ridership\")\r\n\r\nprintln(\"Weather type statistics:\")\r\nweatherTypeStats.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.functions._\r\n//Metro\r\nval weatherTypeStats \u003d Metro_Hourly_Weath_Ridership_DF\r\n  .na.fill(\"Clear\", Seq(\"HourlyWeatherType\")) \r\n  .groupBy(\"HourlyWeatherType\")\r\n  .agg(\r\n    avg(\"total_ridership\").alias(\"mean_ridership\"),\r\n    min(\"total_ridership\").alias(\"min_ridership\"),\r\n    max(\"total_ridership\").alias(\"max_ridership\"),\r\n    stddev(\"total_ridership\").alias(\"stddev_ridership\")\r\n  )\r\n  .orderBy(\"mean_ridership\")\r\n\r\nprintln(\"Weather type statistics:\")\r\nweatherTypeStats.show()"
    }
  ]
}