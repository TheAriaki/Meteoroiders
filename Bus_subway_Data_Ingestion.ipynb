{
  "metadata": {
    "name": "Bus_subway_Data_Ingestion",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Read the bus and subway CSV files\r\nval busFilePath \u003d \"MTA_Bus_Hourly_Ridership__Beginning_February_2022_20240329.csv\"\r\nval subwayFilePath \u003d \"MTA_Subway_Hourly_Ridership__Beginning_February_2022_20240327.csv\"\r\n\r\nval busDf \u003d spark.read\r\n  .option(\"header\", \"true\") \r\n  .option(\"multiLine\", \"true\")\r\n  .option(\"inferSchema\", \"true\")\r\n  .option(\"escape\", \"\\\"\")\r\n  .csv(busFilePath)\r\n\r\nval subwayDf \u003d spark.read\r\n  .option(\"header\", \"true\") \r\n  .option(\"multiLine\", \"true\")\r\n  .option(\"inferSchema\", \"true\")\r\n  .option(\"escape\", \"\\\"\")\r\n  .csv(subwayFilePath)\r\n\r\n// Print the bus and subway DataFrames\r\nprintln(\"Bus DataFrame:\")\r\nz.show(busDf)\r\n\r\nprintln(\"Subway DataFrame:\")\r\nz.show(subwayDf)"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Select specific columns from the bus and subway DataFrames\nval BusbaseDF \u003d busDf.select(\n  \"transit_timestamp\",\n  \"ridership\")\n\nval SubwaybaseDF \u003d subwayDf.select(\n  \"transit_timestamp\",\n  \"ridership\")\n  \n// Cache and count the rows in the bus and subway DataFrames\nBusbaseDF.cache().count\nSubwaybaseDF.cache().count"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(BusbaseDF)\nz.show(SubwaybaseDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(BusbaseDF.describe())\nz.show(SubwaybaseDF.describe())"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Print the schema of the bus DataFrame\nBusbaseDF.printSchema"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.types._\r\n// Convert the transit_timestamp column from string to timestamp format\r\nval timestampColumns \u003d for (x \u003c- BusbaseDF.schema.fields if x.dataType \u003d\u003d StringType \u0026\u0026 x.name \u003d\u003d \"transit_timestamp\") yield x.name\r\n\r\nvar convertedBusDF \u003d BusbaseDF\r\n\r\nfor (c \u003c- timestampColumns)\r\n  convertedBusDF \u003d convertedBusDF.withColumn(c, to_timestamp(col(c), \"MM/dd/yyyy hh:mm:00 a\"))\r\n\r\nz.show(convertedBusDF,10)\r\n\r\nval subwayTimestampColumns \u003d for (x \u003c- SubwaybaseDF.schema.fields if x.dataType \u003d\u003d StringType \u0026\u0026 x.name \u003d\u003d \"transit_timestamp\") yield x.name\r\n\r\nvar convertedSubwayDF \u003d SubwaybaseDF\r\n\r\nfor (c \u003c- subwayTimestampColumns)\r\n  convertedSubwayDF \u003d convertedSubwayDF.withColumn(c, to_timestamp(col(c), \"MM/dd/yyyy hh:mm:00 a\"))\r\n\r\nz.show(convertedSubwayDF,10)"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(BusbaseDF.describe())\nz.show(SubwaybaseDF.describe())"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Find the minimum timestamp in the bus and subway DataFrames\r\nval busMinTimestamp \u003d convertedBusDF.agg(min(\"transit_timestamp\")).first().getTimestamp(0)\r\nprintln(s\"Bus data min timestamp: $busMinTimestamp\")\r\n\r\nval subwayMinTimestamp \u003d convertedSubwayDF.agg(min(\"transit_timestamp\")).first().getTimestamp(0)\r\nprintln(s\"Subway data min timestamp: $subwayMinTimestamp\")"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Find the maximum timestamp in the bus and subway DataFrames\r\nval busMaxTimestamp \u003d convertedBusDF.agg(max(\"transit_timestamp\")).first().getTimestamp(0)\r\nprintln(s\"Bus data max timestamp: $busMaxTimestamp\")\r\n\r\nval subwayMaxTimestamp \u003d convertedSubwayDF.agg(max(\"transit_timestamp\")).first().getTimestamp(0)  \r\nprintln(s\"Subway data max timestamp: $subwayMaxTimestamp\")"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "convertedBusDF.filter($\"ridership\" \u003d\u003d\u003d 0).count"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "convertedSubwayDF.filter($\"ridership\" \u003d\u003d\u003d 0).count"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Check for duplicate timestamps in the bus and subway DataFrames\r\nval busDuplicates \u003d convertedBusDF.groupBy(\"transit_timestamp\").count().filter(\"count \u003e 1\")\r\nprintln(\"Bus data duplicates:\")\r\nz.show(busDuplicates)\r\n\r\nval subwayDuplicates \u003d convertedSubwayDF.groupBy(\"transit_timestamp\").count().filter(\"count \u003e 1\")\r\nprintln(\"Subway data duplicates:\")\r\nz.show(subwayDuplicates)"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Merge the ridership values for duplicate timestamps\r\nval mergedBusDF \u003d convertedBusDF.groupBy(\"transit_timestamp\").agg(sum(\"ridership\").alias(\"total_ridership\"))\r\nprintln(\"Merged bus data:\")\r\nz.show(mergedBusDF)\r\n\r\nval mergedSubwayDF \u003d convertedSubwayDF.groupBy(\"transit_timestamp\").agg(sum(\"ridership\").alias(\"total_ridership\"))\r\nprintln(\"Merged subway data:\")\r\nz.show(mergedSubwayDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Write the cleaned bus and subway DataFrames to Parquet files\nval outputBusPath \u003d \"bus-clean.parquet\"\n\nmergedBusDF.write.mode(\"overwrite\").parquet(outputBusPath)\n\nval outputSubwayPath \u003d \"subway-clean.parquet\"\n\nmergedSubwayDF.write.mode(\"overwrite\").parquet(outputSubwayPath)"
    }
  ]
}